\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{url}

\begin{document}

\title{An alternative formulation and proof of geometric ergodicity for the Poisson INGARCH(1, 1) model}

\maketitle


\section{Alternative formulation}

The INGARCH(1, 1) model is defined as
\begin{align*}
X_t \mid \text{past} & \sim \text{Pois}(\lambda_t)\\
\lambda_t & = \nu + \alpha X_{t - 1} + \beta \lambda_{t - 1}
\end{align*}
with $\lambda_0, X_0$ fixed.

An alternative definition is
\begin{align*}
S_t & = R_t + \kappa \star X_{t - 1}\\
X_t & = S_t - R_t + I_t,\\
R_t & = \beta \circ S_{t}.\\
\end{align*}
Here, the immigrations $I_t$ are defined as
$$
I_t \stackrel{\text{iid}}{\sim} \text{Pois}(\tau).
$$
while the operators $\circ$ and $\star$ denote binomial and Poisson thinning, respectively. To initialize the process we fix $X_t$ and $\lambda_0 > ...$ and sepcify
$$
R_0 \sim \text{Pois}\left(\frac{1 - \phi}{\phi} \times \lambda_0 - \tau \right)
$$

The parameters $\tau, \phi, \kappa$ are linked to those of the original formulation as follows:

$$
<add>
$$

An interpretation is the following:
$$
<add>
$$

\section{An alternative proof of geometric ergodicity and implications on maximum likelihood estimation}

The joint process $(M_t, X_t)$ is a discrete first-order Markov chain with support $\mathbb{N}_0^2$. As $X_{t + 1} + M_{t + 1} \geq M_{1}$, not all states of the Markov chain can be reached from all other states in just one step. However, is it easy to see that this is possible within two steps. E.g., a possibility to move from $(s_t, m_t, x_t)$ to $(s_{t + 2}, m_{t + 2}, x_{t + 1})$ in two steps is the sequence of events
\begin{align*}
M_t & = s_t\\
I_{t + 1} & = s_{t + 2}\\
\end{align*}
implying
\begin{align*}
X_{t + 1} = s_{t + 2}\\
S_{t + 1} = 0\\
M_{t + 1} = 0
\end{align*}
followed by
\begin{align*}
B_{t + 1} = s_{t + 2}.
\end{align*}
This in turn implies
$$
S_{t + 2} = s_{t + 2}
$$
and allows us to also reach
\begin{align*}
X_{t + 2} = x_{t + 2}\\
M_{t + 2} = m_{t + 2}.
\end{align*}
As this obviously has a non-zero probability, the Doeblin condition (\url{https://encyclopediaofmath.org/wiki/Markov_chain,_ergodic}) applies. Consequently, geometric ergodicity of the Markov chain $(S_t, M_t, X_t)$ holds.

Existence of three derivatives of the log likelihood function is shown by Fokianos et al. Then Jensen and Rahbek's law of large numbers for geometrically ergodic processes implies normality of the maximum likelihood estimators.


\subsection{A thinning-based formulation of the INGARCH(1, 1) model}
\label{appendix:ingarch}

We demonstrate that $\{X_t, t = 1, 2, \dots\}$ with
\begin{align}
X_t & = M_t + I_t\label{eq:X_ingarch}\\
S_t & = S_{t - 1} - M_{t - 1} + B_{t - 1} \label{eq:S_ingarch}
\end{align}
where
\begin{align}
M_t & = \phi \circ S_t\\
B_t & = \kappa \star X_t\\
I_t & \stackrel{\text{iid}}{\sim} \text{Pois}(\tau)
\end{align}
is an INGARCH(1, 1) process (with a little particularity, as we shall see in the end). To initialize the process we assume $S_1 = B_{0}; \ \ B_{0} \sim \text{Pois}(\gamma), \gamma > 0$ which implies
$$
X_1 \sim \text{Pois}(\phi\gamma).
$$

We formulate our arguments using a population interpretation of the process, similar to the one from Section \ref{sec:model_definition} / Figure \ref{fig:interpretation}:
\begin{itemize}
\item $S_t$ is the number of juvenile females at time $t$. At each $t$ juveniles transition to fertility with probability $\phi$ (they then enter into $X_t$) and otherwise stay juvenile (move on to $S_{t + 1}$). The number of transitions to fertility in time $t$ is given by $M_t$.
\item $X_t$ is the number of fertile females at time $t$. Females stay fertile for one time period and can each have one or several offspring, their number following a $\text{Pois}(\kappa)$ distribution. Consequently, for the total number of births $B_t$ in time $t$ we have $B_t \mid X_t \sim \text{Pois}(\kappa X_t)$ for $t  =1, 2, \dots$. Females born in $t$ enter into $S_{t + 1}$. The process is initialized by the $B_0$ individuals born into $S_1$.
\item At each time $t$ there is a number $I_t$ of fertile immigrants, independently following a $\text{Pois}(\tau)$ distribution.
\end{itemize}
Now denote by $B_{t, d}$ the number of females born in $t$ and turning fertile in $t + d$, so that $B_t = \sum_{d = 1}^{\infty} B_{t, d}$ holds. The probability that a female born in $t$ becomes fertile in $t + d$ is $(1 - \phi)^d\phi$. From the splitting property of the Poisson distribution (\citealt{Kingman1993}, p.53) it then follows that for a given $t$ and $d = 1, 2, \dots$
$$
B_{t, d} \mid X_t \stackrel{\text{ind}}{\sim} \text{Pois}((1 - \phi)^{d - 1}\phi\kappa X_t).
$$
The definition of the $B_{t, d}$ implies that
$$
X_t = I_t + \sum_{d = 1}^{t} B_{t - d, d}.
$$
Given $X_{t - 1}, \dots, X_1$, the $B_{t - 1, 1},\dots, B_{1, t - 1}, B_{0, t}$ are independent of each other and also of $I_t$ (this is because at each time $t - d$ and given $X_t$, $B_{t - d, d}$ is independent of all $B_{t - d, g}, g < d$ which have already had an impact on the further course of the process). For $t = 2, 3, \dots$ the convolution property of the Poisson distribution then implies
\begin{align*}
X_ t \mid X_{t - 1}, \dots, X_1 & \sim \text{Pois}(\lambda_t)\\
\lambda_t & = \tau \ \ \ + \ \ \ \sum_{d = 1}^{t - 1} \kappa\phi(1 - \phi)^{d - 1}X_{t - d} \ \ \ + \ \ \ (1 - \phi)^{t - 1}\phi\gamma.
\end{align*}
The last term here represents $\mathbb{E}(B_{0, t})$, i.e.\ the expected number of females born into the initial $S_1$ which become fertile in $t$. Now set $\nu = \tau/\phi, \alpha = \phi\kappa, \beta = 1 - \phi$. We can then write
\begin{align*}
\lambda_t & = \frac{\nu}{1 - \beta} \ \ \ + \ \ \ \sum_{d = 1}^{t - 1}\alpha\beta^{d - 1}X_{t - d} \ \ \ + \ \ \ \beta^{t - 1} (1 - \beta)\gamma\\
& = \nu + \beta \cdot \frac{\nu}{1 - \beta} \ \ \ + \ \ \ \alpha X_{t - 1} + \beta \cdot \sum_{d = 1}^{t - 2} \alpha\beta^{d - 1} X_{t - 1 - d}  \ \ \ + \ \ \ \beta \cdot \beta^{t - 2} (1 - \beta)\gamma\\
\end{align*}
For $t = 3, 4, \dots$ this implies
$$
\lambda_t = \nu + \alpha X_{t - 1} + \beta \lambda_{t - 1}.
$$
For $t = 2$ we resort to a little trick: we set $\lambda_1 = (1 - \beta)\gamma + \nu/(1 - \beta)$, despite the fact that $\mathbb{E}(X_1) = (1 - \beta)\gamma$. We then get
\begin{align*}
\mathbb{E}(X_2 \mid X_1) = \lambda_2 & = \nu + \beta \cdot \frac{\nu}{1 - \beta} + \alpha X_1 + \beta(1 - \beta)\gamma\\
& = \nu + \alpha X_1 + \beta \underbrace{\left[(1 - \beta)\gamma + \frac{\nu}{1 - \beta}\right]}_{\:= \lambda_1}
\end{align*}

The process $\{X_t\}$ is thus an INGARCH(1, 1) process, with the particularity that $X_1 \sim\text{Pois}(\lambda_1 - \nu/(1 - \beta))$ instead of $X_1 \sim\text{Pois}(\lambda_1)$.


\end{document}